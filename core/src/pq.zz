using <string.h>::{memcpy, memset};
using <math.h>;
using err;
using endpoint;
using pool;
using log;
using slice;
using channel;
using channel::{FrameType};
using <stdio.h>::{fprintf, stderr};
using hex;
using byteorder;

/// maximum out of order ack before a frame is considered lost
pub const u64 REORDER_THRESHOLD = 3;

/// keepalive
pub const u64 KEEPALIVE = 5000;

/// Don't send TLP faster than x * rtt
pub const u64 MIN_TLP = 5;

/// if nothing was received for x TLPs, the connection is dead
pub const u64 DEAD_TLPS = 20;

/// no packet ever received and we sent that many pings * KEEPALIVE
pub const u64 DEAD_PINGS = 5;

/// each tlp, wait this much longer for a response
pub const u64 BACKOFF = 50;


/// backpressure. queue is full
export symbol MaxQ;

struct Frame {
    u64 mut acked_at;
    u64 mut sent_at;
    u64 packet;

    u8  typ;

    usize mut bufat;
    slice::MutSlice mut buf;
}

/// the outgoing packet queue
export struct Q+ {

    /// how many frames are in queue
    usize mut count;

    /// next position to write, unless count == len(q)
    usize mut head;

    /// next position to read , unless count == 0
    usize mut tail;

    /// current round trip time
    u64 mut rtt;


    // timers
    u64 mut tlp_counter;
    u64 mut time_last_ack_received;
    u64 mut time_last_ping_sent;

    pool::Pool mut* allocator;

    /// ring buffer
    Frame q[];
}


export fn clear(Q+qt mut* self) {
    for (usize mut i = 0; i < qt; i++) {
        if self->q[i].buf.mem != 0 {
            unsafe {
                pool::free(self->allocator, (u8 mut*)(self->q[i].buf.mem));
            }
        }
        memset(self->q + i, 0, sizeof(Frame));
    }
    memset(self, 0, sizeof(Q));
}




/// allocate the next frame in the queue
export fn alloc(Q+qt mut* self, err::Err mut*e, FrameType typ, usize size) -> slice::MutSlice
    where   err::checked(*e)
    model   slice::mut_slice::integrity(&return)
{
    if (self->count + 1 >= qt) {
        err::fail(e, MaxQ, "maxq");
        unsafe {
            slice::MutSlice bad = {0};
            return bad;
        }
    }

    err::assert_safe(self->allocator);
    void mut *payload = self->allocator->malloc(size);
    if payload == 0 {
        err::fail(e, err::OutOfTail, "cannot alloc %u b: %u free", size, self->allocator->free_bytes());
        unsafe {
            slice::MutSlice bad = {0};
            return bad;
        }
    }

    (self->count)++;

    Frame mut* mut r;
    unsafe {
        r = self->q + (self->head)++;
    }
    log::debug("alloc bucket %u|%x", (uint)(self->head-1), r);

    if (self->head >= qt) {
        self->head = 0;
    }

    memset(r, 0, sizeof(Frame));
    static_attest(safe(r));
    r->typ      = (u8)typ;
    r->buf.mem  = payload;
    r->buf.size = size;
    r->buf.at   = &r->bufat;
    static_attest(slice::mut_slice::integrity(&r->buf));


    return r->buf;
}

/// undo last allocation without sending anything
export fn cancel(Q+qt mut* self)
{
    wrapdec(self, &self->head);
    log::debug("cancel bucket %u", self->head);

    unsafe {
        pool::free(self->allocator, (u8 mut*)(self->q[self->head].buf.mem));
    }
    static_attest(self->head < len(self->q));
    memset(self->q + self->head, 0, sizeof(Frame));
    self->count -= 1;
}

export fn window(Q+qt * self) -> usize {
    return qt - self->count;
}

export fn ack(Q+qt mut* self, u64 time, u64 counter) {

    if (counter == 0) {
        return;
    }

    bool mut ack_was_useful = false;

    for let mut it = self->iter(); it.next(); {
        // mark as acked
        if it.f->packet == counter {
            if it.f->typ == 5 {
                u64 order = byteorder::from_be64(unsafe<u64>(* ( (u64*)(it.f->buf.mem + 4))));
                log::debug("  acked packet %zu bucket %zu order %u ", counter, it.i, (uint)order);
            } else {
                log::debug("  acked packet %zu bucket %zu typ %u", counter, it.i, (uint)(it.f->typ));
            }

            it.f->acked_at = time;

            err::assert(time >= it.f->sent_at);

            if (self->rtt == 0) {
                self->rtt = (time - it.f->sent_at);
            } else {
                self->rtt = (self->rtt + (time - it.f->sent_at)) / 2;
            }
            if (self->rtt == 0) {
                self->rtt = 1;
            }

            ack_was_useful = true;
        }
    }

    if ack_was_useful {
        self->time_last_ack_received = time;
        self->tlp_counter = 0;


        // as long as the tail is acked, clear the tail and advance

        for let mut it = self->iter(); it.next(); {
            if it.f->acked_at != 0 {
                log::debug("  clear bucket %u ", (uint)it.i);

                unsafe {
                    pool::free(self->allocator, (u8 mut*)it.f->buf.mem);
                }

                memset(it.f, 0, sizeof(Frame));
                (self->tail)++;
                (self->count)--;
                if (self->tail  >= qt) {
                    self->tail = 0;
                }
            } else {
                break;
            }
        }
    }


}


/// tail loss probe or ping and return the time when we need to call this function again
export fn keepalive(Q+qt mut* self, u64 now) -> u64
{
    if self->tlp_counter >= DEAD_TLPS {
        log::debug("sent %u tlps, but last ack was seen %u ms ago",
            (uint)self->tlp_counter,
            (uint)(now - self->time_last_ack_received)
        );
        return 0;
    }

    let mut ref_time = self->time_last_ack_received;
    if self->time_last_ping_sent > ref_time {
        ref_time = self->time_last_ping_sent;
    }


    //log::debug("count: %u | now: %u | ref_time: %u | rtt: %u", self->count, now, ref_time, self->rtt);

    // if the last ack was 2 * rtt ago, resend the oldest not-ack'd packet
    if self->count > 0 && ref_time != 0 && self->rtt != 0 {
        let mut tt = (2 * self->rtt) + (self->tlp_counter * BACKOFF);
        if tt < MIN_TLP {
            tt = MIN_TLP;
        }

        if ref_time == now {
            return tt;
        }

        if now >= tt + ref_time {
            self->time_last_ping_sent = now;
            log::debug("TLP %u, was expected within %zu ms at rtt current %zu", self->tlp_counter, tt, self->rtt);

            static_attest(self->tail < len(self->q));

            // TODO ideally we'd keep the old pkt market somehow, because we still may get the delayed ack,
            // but might loose the new packet this is now resent in

            bool mut did_mark_some = false;
            //self->dump();
            // mark all old frames as lost
            for (usize mut i = 0; i < qt; i++) {
                if self->q[i].sent_at != 0              // if this bucket was sent before
                    && self->q[i].acked_at == 0         // but not ackd
                    && now >= self->q[i].sent_at + tt   // and it was sent more than headoff period ago
                    {


                        if self->q[i].typ == 5 {
                            u64 order = byteorder::from_be64(unsafe<u64>(* ( (u64*)(self->q[i].buf.mem + 4))));
                            log::debug("  resend bucket %u (lost in pkt %u) typ %u order %u",
                                    (uint)i, (uint)(self->q[i].packet), (uint)(self->q[i].typ), (uint)(order));

                        } else {
                            log::debug("  resend bucket %u (lost in pkt %u) typ %u size %u",
                                    (uint)i, (uint)(self->q[i].packet), (uint)(self->q[i].typ), (uint)(self->q[i].buf.at));
                        }

                    //unsafe {
                    //    hex::dump(self->q[i].buf.slice.mem, self->q[i].buf.at);
                    //}


                    self->q[i].sent_at = 0;

                    did_mark_some = true;
                }
            }

            //self->dump();

            if did_mark_some {
                self->tlp_counter += 1;
            }
            return tt;
        }
        return ref_time + tt - now;
    }


    // if there's nothing to dequeue, just send pings every KEEPALIVE ms
    let tt = KEEPALIVE + (self->tlp_counter * BACKOFF);
    if now >= tt + ref_time {
        self->tlp_counter += 1;
        if self->tlp_counter >= DEAD_PINGS {
            return 0;
        }
        self->time_last_ping_sent = now;
        //log::debug("sending ping %u, expected in %zu", self->tlp_counter, tt);

        new+10 e = err::make();
        let mut *frame = self->alloc(&e, channel::FrameType::Ping, 1);
        return tt;
    }
    return ref_time + tt - now;
}



// learning: don't use frame->buf.at.
// the frame is memcpyied in recovery, and that pointer is wrong
fn make_frame_size(Frame mut* frame)
{
    static_attest(slice::mut_slice::integrity(&frame->buf));

    switch frame->typ {
        channel::FrameType::Ack         => {}
        channel::FrameType::Ping        => {}
        channel::FrameType::Disconnect  => {}
        channel::FrameType::Open        => {
            err::assert(frame->buf.size >= 4 + 2 + 4);
            u16 bsize = byteorder::to_be16(frame->bufat - 4 - 2);
            memcpy(frame->buf.mem + 4, &bsize, 2);
            err::assert(unsafe<bool>(frame->bufat   >= 4 + 2 + 4));
        }
        channel::FrameType::Stream => {
            err::assert(frame->buf.size >= 4 + 8 + 2);
            u16 bsize = byteorder::to_be16(frame->bufat - 4 - 8 - 2);
            memcpy(frame->buf.mem + 4 + 8, &bsize, 2);
            err::assert(unsafe<bool>(frame->bufat   >= 4 + 8 + 2));
        }
        channel::FrameType::Close => {
            err::assert(frame->bufat == 13 || frame->bufat == 12);
        }
    }
}

/// send frames out of the queue
export fn send(Q+qt mut* self, u64 time, u8 mut* buf , u16 buflen, u64 counter) -> usize {
    err::assert(time != 0);

    log::debug("q::send | self->count: %u | self->tail: %u | self->head: %u |",
        (uint)self->count,
        (uint)self->tail,
        (uint)self->head
    );

    u16 mut sent_bytes = 0;

    for let mut it = self->iter(); it.next(); {
        Frame mut* f = it.f;

        if f->sent_at == 0 && f->typ == 0 {
            // should be fixed now
            log::warn("BUG: bucket %u has f->typ == 0", (uint)it.i);
        }

        if (f->sent_at == 0 && f->typ != 0) {

            if ((sent_bytes + (u16)f->bufat + 1) > buflen) {
                break;
            }

            make_frame_size(f);
            if f->typ == 5 {
                u64 order = byteorder::from_be64(unsafe<u64>(* ( (u64*)(f->buf.mem + 4))));
                log::debug("bucket %u (typ: %u, size %u, order %u), sent in pkt %u",
                    (uint)it.i,
                    (uint)f->typ,
                    (uint)f->bufat,
                    (uint)order,
                    (uint)counter
                );


            } else {
                log::debug("bucket %u (typ: %u, size %u), sent in pkt %u",
                    (uint)it.i,
                    (uint)f->typ,
                    (uint)f->bufat,
                    (uint)counter
                );
            }


            f->packet   = counter;
            f->sent_at  = time;

            unsafe {
                memcpy(buf + sent_bytes, &f->typ, 1);
            }
            sent_bytes += 1;

            unsafe {
                memcpy(buf + sent_bytes, (u8 mut*)f->buf.mem, f->bufat);
            }
            sent_bytes += (u16)f->bufat;

            // we never send more than one now
            break;
        }
    }
    return (usize)sent_bytes;
}



struct Iterator {
    Q * q;
    usize qt;
    usize count;
    usize i;
    Frame mut * f;
}

fn iter(Q+qt * self) Iterator {
    return Iterator {
        q:              self,
        qt:             qt,
        count:          self->count,
        i:              self->tail - 1, // unsigned overflow is fine, because nothing uses it before next()
    };
}

fn next(Iterator mut *self) bool
    model safe(self->f)
{
    if self->count == 0 {
        self->f = 0;
        static_attest(safe(self->f));
        return false;
    }

    self->count -= 1;
    self->i += 1;
    if self->i >= self->qt {
        self->i = 0;
    }
    unsafe {
        self->f = (Frame mut*)(self->q->q + self->i);
    }
    static_attest(safe(self->f));
    return true;
}

fn wrapdec (Q+qt * self, usize mut* i) -> usize {
    *i is safe;
    usize v = *i;
    if (*i == 0) {
        *i = qt;
    }
    (*i)--;
    return v;
}


/*
pub fn dump(Q+qt * self) {
unsafe{
    fprintf(stderr,"===================================================================\n");
    fprintf(stderr,"      ");
    for (int mut i = 0; i < qt; i++) {
        fprintf(stderr,"%02d ", i);
    }
    //fprintf(stderr,"\nmark  ");
    //for (int mut i = 0; i < qt; i++) {
    //    if (((self->q)[i]).marker != 0) {
    //        fprintf(stderr,"%02d ", ((self->q)[i]).marker);
    //    } else {
    //        fprintf(stderr,"   ");
    //    }
    //}
    fprintf(stderr,"\npckt  ");
    for (int mut i = 0; i < qt; i++) {
        if (((self->q)[i]).packet != 0) {
            fprintf(stderr,"%02lu ", ((self->q)[i]).packet);
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\nackd  ");
    for (int mut i = 0; i < qt; i++) {
        if (((self->q)[i]).acked_at != 0) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\ntail ");
    for (int mut i = 0; i < qt; i++) {
        if (i == self->tail) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\nhead  ");
    for (int mut i = 0; i < qt; i++) {
        if (i == self->head) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\nsent  ");
    for (int mut i = 0; i < qt; i++) {
        if (i == self->sent) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\n===================================================================\n");
}
}

*/
