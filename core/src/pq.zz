using <string.h>::{memcpy, memset};
using <math.h>;
using <assert.h>::{assert};
using err;
using endpoint;
using pool;
using log;
using slice;
using channel;
using channel::{FrameType};
using <stdio.h>::{fprintf, stderr};
using hex;
using byteorder;

/// maximum out of order ack before a frame is considered lost
pub const u64 REORDER_THRESHOLD = 3;

/// keepalive
pub const u64 KEEPALIVE = 5000;

/// Don't send TLP faster than x * rtt
pub const u64 MIN_TLP = 5;

/// if nothing was received for x TLPs, the connection is dead
pub const u64 DEAD_TLPS = 20;

/// no packet ever received and we sent that many pings * KEEPALIVE
pub const u64 DEAD_PINGS = 5;

/// each tlp, wait this much longer for a response
pub const u64 BACKOFF = 50;


/// backpressure. queue is full
export symbol MaxQ;

struct Frame {
    u64 mut acked_at;
    u64 mut sent_at;
    u64 packet;

    u8  typ;

    usize mut bufat;
    slice::MutSlice mut buf;
}

/// the outgoing packet queue
export struct Q+ {

    /// how many frames are in queue
    usize mut count;

    /// the next unused entry
    usize mut back;

    /// first used entry in the ring, anything left of this was acked and can be reused
    usize mut front;

    /// to the left is sent but not acked frames, to the right is frames we send next
    usize mut sent;

    /// current round trip time
    u64 mut rtt;


    // timers
    u64 mut tlp_counter;
    u64 mut time_last_ack_received;
    u64 mut time_last_ping_sent;

    pool::Pool mut* allocator;


    /// revision of peer for bug workarounds
    u32     revision;


    /// ring buffer
    Frame q[];
}


export fn clear(Q+qt mut* self) {
    for (usize mut i = 0; i < qt; i++) {
        if self->q[i].buf.mem != 0 {
            unsafe {
                pool::free(self->allocator, (u8 mut*)(self->q[i].buf.mem));
            }
        }
        memset(self->q + i, 0, sizeof(Frame));
    }
    memset(self, 0, sizeof(Q));
}




/// allocate the next frame in the queue
export fn alloc(Q+qt mut* self, err::Err mut*e, FrameType typ, usize size) -> slice::MutSlice
    where   err::checked(*e)
    model   slice::mut_slice::integrity(&return)
{
    err::assert_safe(self->allocator);
    void mut *payload = self->allocator->malloc(size);
    if payload == 0 {
        err::fail(e, err::OutOfTail, "cannot alloc %u b: %u free", size, self->allocator->free_bytes());
        unsafe {
            slice::MutSlice bad = {0};
            return bad;
        }
    }

    Frame mut* mut r;
    if (self->count + 1 >= qt) {
        self->allocator->free(payload);
        err::fail(e, MaxQ, "maxq");
        unsafe {
            slice::MutSlice bad = {0};
            return bad;
        }
    }
    (self->count)++;

    unsafe {
        r = self->q + (self->back)++;
    }
    log::debug("alloc bucket %u|%x", (uint)(self->back-1), r);

    if (self->back >= qt) {
        self->back = 0;
    }

    memset(r, 0, sizeof(Frame));
    static_attest(safe(r));
    r->typ      = (u8)typ;
    r->buf.mem  = payload;
    r->buf.size = size;
    r->buf.at   = &r->bufat;
    static_attest(slice::mut_slice::integrity(&r->buf));


    return r->buf;
}

/// undo last allocation without sending anything
export fn cancel(Q+qt mut* self)
{
    wrapdec(self, &self->back);
    log::debug("cancel bucket %u", self->back);

    unsafe {
        pool::free(self->allocator, (u8 mut*)(self->q[self->back].buf.mem));
    }
    static_attest(self->back < len(self->q));
    memset(self->q + self->back, 0, sizeof(Frame));
    self->count -= 1;
}

export fn window(Q+qt * self) -> usize {
    return qt- self->count;
}

export fn ack(Q+qt mut* self, u64 time, u64 counter) {
    if (counter == 0) {
        return;
    }
    //log::debug("ack: %lu, front: %lu, count: %zu, back:%zu", counter, self->front, self->count, self->back);



    Frame mut* mut qq = self->q;
    usize mut f = self->front;

    bool mut ack_was_useful = false;

    for (usize mut i = 0; i < qt; wrapinc(self, &f), i++) {
        static_attest(f < len(qq));
        // mark as acked
        if ((qq[f]).packet == counter) {


            if qq[f].typ == 5 {
                u64 order = byteorder::from_be64(unsafe<u64>(* ( (u64*)(qq[f].buf.mem + 4))));
                log::debug("  acked packet %zu bucket %zu order %u ", counter, f, (uint)order);
            } else {
                log::debug("  acked packet %zu bucket %zu typ %u", counter, f, (uint)qq[f].typ);
            }

            (qq[f]).acked_at = time;

            assert(time >= qq[f].sent_at);

            if (self->rtt == 0) {
                self->rtt = (time - (qq[f]).sent_at);
            } else {
                self->rtt = (self->rtt + (time - (qq[f]).sent_at)) / 2;
            }
            if (self->rtt == 0) {
                self->rtt = 1;
            }

            ack_was_useful = true;
        }

        // as long as the front is acked, clear the front and advance
        if (f == self->front && (qq[f]).acked_at != 0) {
            static_attest(safe(self->allocator));

            log::debug("  clear bucket %u ", (uint)f);

            unsafe {
                pool::free(self->allocator, (u8 mut*)(qq[f].buf.mem));
            }

            memset(qq + f, 0, sizeof(Frame));
            (self->front)++;
            (self->count)--;
            if (self->front  >= qt) {
                self->front = 0;
            }
        } else if ((qq[f]).packet > counter || f == self->sent) {
            //log::debug("  pk: %lu, co: %zu", (qq[f]).packet, counter);
            break;
        }

        // TODO some testing suggests resending misordered packets early instead of waiting for TLP leads to worse performance,
        // but its unclear if this was just a side effect from the ack bug in <= 176


        // if this frame is not acked and too far behind, move it back to the front of the queue
        if ((qq[f]).acked_at == 0 && (qq[f]).packet > 0 && (qq[f]).packet + REORDER_THRESHOLD < counter) {
            (qq[f]).sent_at = 0;
            (qq[f]).packet  = 0;

            Frame mut mov;
            // copy the frame to be moved
            memcpy(&mov, &(qq[f]), sizeof(Frame));
            // zero the bucket where it was located
            memset(qq + f, 0, sizeof(Frame));
            wrapinc(self, &self->front);

            //TODO why?
            mov.buf.at = 0;

            // move everything one to the right
            for (usize mut i = wrapinc(self, &self->back); i != self->sent;) {
                usize p    = wrapdec(self, &i);
                unsafe {
                    memcpy(qq + p, qq + i, sizeof(Frame));
                }
                log::debug("  bucket %u moved to bucket %u", (uint)i, (uint)p);
            }

            unsafe {
                memcpy(qq + self->sent, &mov, sizeof(Frame));
            }
            log::debug("  bucket %u moved to bucket %u, because it is behind REORDER_THRESHOLD", (uint)f, (uint)self->sent);


        }

        if (f == self->back) {
            break;
        }


    }

    if ack_was_useful {
        self->time_last_ack_received = time;
        self->tlp_counter = 0;
    }

}


/// tail loss probe or ping and return the time when we need to call this function again
export fn keepalive(Q+qt mut* self, u64 now) -> u64
{
    if self->tlp_counter >= DEAD_TLPS {
        log::debug("sent %u tlps, but last ack was seen %u ms ago",
            (uint)self->tlp_counter,
            (uint)(now - self->time_last_ack_received)
        );
        return 0;
    }

    let mut ref_time = self->time_last_ack_received;
    if self->time_last_ping_sent > ref_time {
        ref_time = self->time_last_ping_sent;
    }


    //log::debug("count: %u | now: %u | ref_time: %u | rtt: %u", self->count, now, ref_time, self->rtt);

    // if the last ack was 2 * rtt ago, resend the oldest not-ack'd packet
    if self->count > 0 && ref_time != 0 && self->rtt != 0 {
        let mut tt = (2 * self->rtt) + (self->tlp_counter * BACKOFF);
        if tt < MIN_TLP {
            tt = MIN_TLP;
        }

        if ref_time == now {
            return tt;
        }

        if now >= tt + ref_time {
            self->time_last_ping_sent = now;
            log::debug("TLP %u, was expected within %zu ms at rtt current %zu", self->tlp_counter, tt, self->rtt);

            static_attest(self->front < len(self->q));

            // TODO ideally we'd keep the old pkt market somehow, because we still may get the delayed ack,
            // but might loose the new packet this is now resent in

            bool mut did_mark_some = false;
            //self->dump();
            // mark all old frames as lost
            for (usize mut i = 0; i < qt; i++) {
                if self->q[i].sent_at != 0              // if this bucket was sent before
                    && self->q[i].acked_at == 0         // but not ackd
                    && now >= self->q[i].sent_at + tt   // and it was sent more than backoff period ago
                    {


                        if self->q[i].typ == 5 {
                            u64 order = byteorder::from_be64(unsafe<u64>(* ( (u64*)(self->q[i].buf.mem + 4))));
                            log::debug("  resend bucket %u (lost in pkt %u) typ %u order %u",
                                    (uint)i, (uint)(self->q[i].packet), (uint)(self->q[i].typ), (uint)(order));

                        } else {
                            log::debug("  resend bucket %u (lost in pkt %u) typ %u size %u",
                                    (uint)i, (uint)(self->q[i].packet), (uint)(self->q[i].typ), (uint)(self->q[i].buf.at));
                        }

                    //unsafe {
                    //    hex::dump(self->q[i].buf.slice.mem, self->q[i].buf.at);
                    //}


                    self->q[i].sent_at = 0;

                    did_mark_some = true;
                }
            }
            // reset the sent pointer to the front. send() will reiterate
            self->sent = self->front;

            //self->dump();

            if did_mark_some {
                self->tlp_counter += 1;
            }
            return tt;
        }
        return ref_time + tt - now;
    }


    // if there's nothing to dequeue, just send pings every KEEPALIVE ms
    let tt = KEEPALIVE + (self->tlp_counter * BACKOFF);
    if now >= tt + ref_time {
        self->tlp_counter += 1;
        if self->tlp_counter >= DEAD_PINGS {
            return 0;
        }
        self->time_last_ping_sent = now;
        //log::debug("sending ping %u, expected in %zu", self->tlp_counter, tt);

        new+10 e = err::make();
        let mut *frame = self->alloc(&e, channel::FrameType::Ping, 1);
        return tt;
    }
    return ref_time + tt - now;
}



// learning: don't use frame->buf.at.
// the frame is memcpyied in recovery, and that pointer is wrong
fn make_frame_size(Frame mut* frame)
{
    static_attest(slice::mut_slice::integrity(&frame->buf));

    switch frame->typ {
        channel::FrameType::Ack         => {}
        channel::FrameType::Ping        => {}
        channel::FrameType::Disconnect  => {}
        channel::FrameType::Open        => {
            err::assert(frame->buf.size >= 4 + 2 + 4);
            u16 bsize = byteorder::to_be16(frame->bufat - 4 - 2);
            memcpy(frame->buf.mem + 4, &bsize, 2);
            err::assert(unsafe<bool>(frame->bufat   >= 4 + 2 + 4));
        }
        channel::FrameType::Stream => {
            err::assert(frame->buf.size >= 4 + 8 + 2);
            u16 bsize = byteorder::to_be16(frame->bufat - 4 - 8 - 2);
            memcpy(frame->buf.mem + 4 + 8, &bsize, 2);
            err::assert(unsafe<bool>(frame->bufat   >= 4 + 8 + 2));
        }
        channel::FrameType::Close => {
            err::assert(frame->bufat == 13 || frame->bufat == 12);
        }
    }
}

/// send frames out of the queue
export fn send(Q+qt mut* self, u64 time, u8 mut* buf , u16 buflen, u64 counter) -> usize {
    assert(time != 0);

    log::debug("q::send | self->sent: %u | self->back: %u |",
        (uint)self->sent,
        (uint)self->back
    );

    static_attest(self->sent < len(self->q));

    usize mut sent_frames_in_packet = 0;
    u16 mut sent_bytes = 0;
    for (;(self->sent != self->back) && sent_bytes < 600; ) {

        // workaround for in 176, where peer will send ack if ANY of the frames in the packet is ackd
        if self->revision <= 176 {
            if sent_frames_in_packet >0 {
                break;
            }
        }

        Frame mut* f = &((self->q)[self->sent]);

        if f->sent_at == 0 && f->typ == 0 {
            log::warn("BUG: bucket %u has f->typ == 0", (uint)self->sent);
        }

        if (f->sent_at == 0 && f->typ != 0 /*TODO how does this happen?*/) {

            if ((sent_bytes + (u16)f->bufat + 1) > buflen) {
                break;
            }

            make_frame_size(f);
            if f->typ == 5 {
                u64 order = byteorder::from_be64(unsafe<u64>(* ( (u64*)(f->buf.mem + 4))));
                log::debug("bucket %u (typ: %u, size %u, order %u), sent in pkt %u",
                    (uint)self->sent,
                    (uint)f->typ,
                    (uint)f->bufat,
                    (uint)order,
                    (uint)counter
                );


            } else {
                log::debug("bucket %u (typ: %u, size %u), sent in pkt %u",
                    (uint)self->sent,
                    (uint)f->typ,
                    (uint)f->bufat,
                    (uint)counter
                );
            }


            f->packet   = counter;
            f->sent_at  = time;

            unsafe {
                memcpy(buf + sent_bytes, &f->typ, 1);
            }
            sent_bytes += 1;

            unsafe {
                memcpy(buf + sent_bytes, (u8 mut*)f->buf.mem, f->bufat);
            }
            sent_bytes += (u16)f->bufat;
            sent_frames_in_packet += 1;
        }
        (self->sent)++;
        if (self->sent >= qt) {
            self->sent = 0;
        }
    }
    return (usize)sent_bytes;
}

fn wrapinc (Q+qt * self, usize mut* i) -> usize {
    *i is safe;
    usize v = (*i)++;
    if (*i >= qt) {
        *i = 0;
    }
    return v;
}

fn wrapdec (Q+qt * self, usize mut* i) -> usize {
    *i is safe;
    usize v = *i;
    if (*i == 0) {
        *i = qt;
    }
    (*i)--;
    return v;
}


/*
pub fn dump(Q+qt * self) {
unsafe{
    fprintf(stderr,"===================================================================\n");
    fprintf(stderr,"      ");
    for (int mut i = 0; i < qt; i++) {
        fprintf(stderr,"%02d ", i);
    }
    //fprintf(stderr,"\nmark  ");
    //for (int mut i = 0; i < qt; i++) {
    //    if (((self->q)[i]).marker != 0) {
    //        fprintf(stderr,"%02d ", ((self->q)[i]).marker);
    //    } else {
    //        fprintf(stderr,"   ");
    //    }
    //}
    fprintf(stderr,"\npckt  ");
    for (int mut i = 0; i < qt; i++) {
        if (((self->q)[i]).packet != 0) {
            fprintf(stderr,"%02lu ", ((self->q)[i]).packet);
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\nackd  ");
    for (int mut i = 0; i < qt; i++) {
        if (((self->q)[i]).acked_at != 0) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\nfront ");
    for (int mut i = 0; i < qt; i++) {
        if (i == self->front) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\nback  ");
    for (int mut i = 0; i < qt; i++) {
        if (i == self->back) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\nsent  ");
    for (int mut i = 0; i < qt; i++) {
        if (i == self->sent) {
            fprintf(stderr,"x  ");
        } else {
            fprintf(stderr,"   ");
        }
    }
    fprintf(stderr,"\n===================================================================\n");
}
}

*/
